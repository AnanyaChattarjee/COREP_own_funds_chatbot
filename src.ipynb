{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a67cc778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pypdf import PdfReader\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "from google import genai\n",
    "\n",
    "from api_key import API_KEY\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d56a8895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts all text from a given PDF file.\"\"\"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    full_text = \"\"\n",
    "    for page in reader.pages:\n",
    "        full_text += page.extract_text() or \"\" \n",
    "    return full_text\n",
    "\n",
    "\n",
    "file_path1 = 'documents/corep-own-funds-instructions.pdf'\n",
    "file_path2 = 'documents/Reporting (CRR)_06-02-2026.pdf'\n",
    "own_funds_instructions = extract_text_from_pdf(file_path1)\n",
    "reporting_crr = extract_text_from_pdf(file_path2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d1b6fe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586822 83341\n"
     ]
    }
   ],
   "source": [
    "print(len(own_funds_instructions), len(reporting_crr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "27fdd78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 587\n",
      "After: 562\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>corep_0000</td>\n",
       "      <td>erage;  \\n(b) group solvency, an overview of t...</td>\n",
       "      <td>COREP_Annex_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corep_0001</td>\n",
       "      <td>rows and cells of the templates. Those numeri...</td>\n",
       "      <td>COREP_Annex_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corep_0002</td>\n",
       "      <td>Abbreviations  \\n10. For the purposes of thi...</td>\n",
       "      <td>COREP_Annex_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corep_0003</td>\n",
       "      <td>s of certain types of undertakings, amending D...</td>\n",
       "      <td>COREP_Annex_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corep_0004</td>\n",
       "      <td>\\n11. The CA templates contain information abo...</td>\n",
       "      <td>COREP_Annex_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>corep_0557</td>\n",
       "      <td>(row 0060), the part of NPEs secured by immov...</td>\n",
       "      <td>COREP_Annex_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>corep_0558</td>\n",
       "      <td>er Article 47c(6) CRR secured by immovable pro...</td>\n",
       "      <td>COREP_Annex_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>corep_0559</td>\n",
       "      <td>tion of the exposure as non-performing.  \\nEff...</td>\n",
       "      <td>COREP_Annex_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>corep_0560</td>\n",
       "      <td>ints (a), (b), (c), (e) and (g) of Article 47c...</td>\n",
       "      <td>COREP_Annex_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>corep_0561</td>\n",
       "      <td>of the exposure as non-performing.  \\n0150  &gt; ...</td>\n",
       "      <td>COREP_Annex_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>562 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       chunk_id                                               text  \\\n",
       "0    corep_0000  erage;  \\n(b) group solvency, an overview of t...   \n",
       "1    corep_0001   rows and cells of the templates. Those numeri...   \n",
       "2    corep_0002    Abbreviations  \\n10. For the purposes of thi...   \n",
       "3    corep_0003  s of certain types of undertakings, amending D...   \n",
       "4    corep_0004  \\n11. The CA templates contain information abo...   \n",
       "..          ...                                                ...   \n",
       "557  corep_0557   (row 0060), the part of NPEs secured by immov...   \n",
       "558  corep_0558  er Article 47c(6) CRR secured by immovable pro...   \n",
       "559  corep_0559  tion of the exposure as non-performing.  \\nEff...   \n",
       "560  corep_0560  ints (a), (b), (c), (e) and (g) of Article 47c...   \n",
       "561  corep_0561  of the exposure as non-performing.  \\n0150  > ...   \n",
       "\n",
       "             source  \n",
       "0    COREP_Annex_II  \n",
       "1    COREP_Annex_II  \n",
       "2    COREP_Annex_II  \n",
       "3    COREP_Annex_II  \n",
       "4    COREP_Annex_II  \n",
       "..              ...  \n",
       "557  COREP_Annex_II  \n",
       "558  COREP_Annex_II  \n",
       "559  COREP_Annex_II  \n",
       "560  COREP_Annex_II  \n",
       "561  COREP_Annex_II  \n",
       "\n",
       "[562 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = list()\n",
    "i =0\n",
    "while (i < len(own_funds_instructions)):\n",
    "    row = {'chunk_id': 'corep_'+str(int(i/1000)),'text':own_funds_instructions[i:i+1200]\t,'source':'COREP_Annex_II'}\n",
    "    i=i+1000\n",
    "    data_list.append(row)\n",
    "\n",
    "data1=pd.DataFrame(data_list)\n",
    "def is_junk_chunk(text, min_len=200):\n",
    "    if not isinstance(text, str):\n",
    "        return True\n",
    "\n",
    "    t = text.strip()\n",
    "\n",
    "    if len(t) < min_len:\n",
    "        return True\n",
    "\n",
    "    no_space = re.sub(r\"\\s+\", \"\", t)\n",
    "\n",
    "    # mostly punctuation/dots\n",
    "    if len(re.sub(r\"[A-Za-z0-9]\", \"\", no_space)) / len(no_space) > 0.85:\n",
    "        return True\n",
    "\n",
    "    # long dotted separator\n",
    "    if re.search(r\"\\.{15,}\", t):\n",
    "        return True\n",
    "\n",
    "    # very low alphabetic content\n",
    "    alpha_chars = sum(c.isalpha() for c in t)\n",
    "    if alpha_chars / len(t) < 0.15:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "data1_clean = data1.copy()\n",
    "data1_clean[\"is_junk\"] = data1_clean[\"text\"].apply(is_junk_chunk)\n",
    "\n",
    "print(\"Before:\", len(data1_clean))\n",
    "\n",
    "data1_clean = data1_clean[data1_clean[\"is_junk\"] == False] \\\n",
    "    .drop(columns=[\"is_junk\"]) \\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "print(\"After:\", len(data1_clean))\n",
    "# Separate COREP and PRA\n",
    "corep_df = data1_clean[data1_clean[\"source\"] == \"COREP_Annex_II\"].copy().reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Reassign sequential chunk_ids\n",
    "corep_df[\"chunk_id\"] = [f\"corep_{i:04d}\" for i in range(len(corep_df))]\n",
    "\n",
    "\n",
    "# Merge back\n",
    "data1 = pd.concat([corep_df], ignore_index=True)\n",
    "\n",
    "# Check\n",
    "data1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b806b7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 84\n",
      "After: 84\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pra_0000</td>\n",
       "      <td>Prudential Regulation Authority Rulebook\\nPart...</td>\n",
       "      <td>PRA_RULEBOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pra_0001</td>\n",
       "      <td>s\\n1.1 This Part applies to:\\n(a) a firm that ...</td>\n",
       "      <td>PRA_RULEBOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pra_0002</td>\n",
       "      <td>5 and annexes X and XI of\\nChapter 6.\\n31/12/...</td>\n",
       "      <td>PRA_RULEBOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pra_0003</td>\n",
       "      <td>s on a consolidated basis\\n2.4 A CRR consolida...</td>\n",
       "      <td>PRA_RULEBOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pra_0004</td>\n",
       "      <td>'consolidation situation' is defined in Artic...</td>\n",
       "      <td>PRA_RULEBOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>pra_0079</td>\n",
       "      <td>.246 [Deleted.]\\n01/09/2022\\n2.247 [Deleted.]0...</td>\n",
       "      <td>PRA_RULEBOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>pra_0080</td>\n",
       "      <td>22\\n6.257 [Note: Provision left blank]\\n01/09/...</td>\n",
       "      <td>PRA_RULEBOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>pra_0081</td>\n",
       "      <td>/09/2022\\n6.269 Annex XVI Template F 32.04 can...</td>\n",
       "      <td>PRA_RULEBOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>pra_0082</td>\n",
       "      <td>found here\\nO .\\n01/09/2022\\n6.279 Annex XVII...</td>\n",
       "      <td>PRA_RULEBOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>pra_0083</td>\n",
       "      <td>022\\n2.287 [Deleted.]\\n01/09/2022\\n2.288 [Dele...</td>\n",
       "      <td>PRA_RULEBOOK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    chunk_id                                               text        source\n",
       "0   pra_0000  Prudential Regulation Authority Rulebook\\nPart...  PRA_RULEBOOK\n",
       "1   pra_0001  s\\n1.1 This Part applies to:\\n(a) a firm that ...  PRA_RULEBOOK\n",
       "2   pra_0002   5 and annexes X and XI of\\nChapter 6.\\n31/12/...  PRA_RULEBOOK\n",
       "3   pra_0003  s on a consolidated basis\\n2.4 A CRR consolida...  PRA_RULEBOOK\n",
       "4   pra_0004   'consolidation situation' is defined in Artic...  PRA_RULEBOOK\n",
       "..       ...                                                ...           ...\n",
       "79  pra_0079  .246 [Deleted.]\\n01/09/2022\\n2.247 [Deleted.]0...  PRA_RULEBOOK\n",
       "80  pra_0080  22\\n6.257 [Note: Provision left blank]\\n01/09/...  PRA_RULEBOOK\n",
       "81  pra_0081  /09/2022\\n6.269 Annex XVI Template F 32.04 can...  PRA_RULEBOOK\n",
       "82  pra_0082   found here\\nO .\\n01/09/2022\\n6.279 Annex XVII...  PRA_RULEBOOK\n",
       "83  pra_0083  022\\n2.287 [Deleted.]\\n01/09/2022\\n2.288 [Dele...  PRA_RULEBOOK\n",
       "\n",
       "[84 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list_new = list()\n",
    "i =0\n",
    "while (i < len(reporting_crr)):\n",
    "    row = {'chunk_id': 'pra_'+str(int(i/1000)),'text':reporting_crr[i:i+1200]\t,'source':'PRA_RULEBOOK'}\n",
    "    i=i+1000\n",
    "    data_list_new.append(row)\n",
    "\n",
    "data2=pd.DataFrame(data_list_new)\n",
    "def is_junk_chunk(text, min_len=200):\n",
    "    if not isinstance(text, str):\n",
    "        return True\n",
    "\n",
    "    t = text.strip()\n",
    "\n",
    "    if len(t) < min_len:\n",
    "        return True\n",
    "\n",
    "    no_space = re.sub(r\"\\s+\", \"\", t)\n",
    "\n",
    "    # mostly punctuation/dots\n",
    "    if len(re.sub(r\"[A-Za-z0-9]\", \"\", no_space)) / len(no_space) > 0.85:\n",
    "        return True\n",
    "\n",
    "    # long dotted separator\n",
    "    if re.search(r\"\\.{15,}\", t):\n",
    "        return True\n",
    "\n",
    "    # very low alphabetic content\n",
    "    alpha_chars = sum(c.isalpha() for c in t)\n",
    "    if alpha_chars / len(t) < 0.15:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "data2_clean = data2.copy()\n",
    "data2_clean[\"is_junk\"] = data2_clean[\"text\"].apply(is_junk_chunk)\n",
    "\n",
    "print(\"Before:\", len(data2_clean))\n",
    "\n",
    "data2_clean = data2_clean[data2_clean[\"is_junk\"] == False] \\\n",
    "    .drop(columns=[\"is_junk\"]) \\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "print(\"After:\", len(data2_clean))\n",
    "pra_df   = data2_clean[data2_clean[\"source\"] == \"PRA_RULEBOOK\"].copy().reset_index(drop=True)\n",
    "\n",
    "pra_df[\"chunk_id\"]   = [f\"pra_{i:04d}\" for i in range(len(pra_df))]\n",
    "\n",
    "# Merge back\n",
    "data2 = pd.concat([ pra_df], ignore_index=True)\n",
    "\n",
    "# Check\n",
    "data2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab67b494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>corep_0000</td>\n",
       "      <td>erage;  \\n(b) group solvency, an overview of t...</td>\n",
       "      <td>COREP_Annex_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corep_0001</td>\n",
       "      <td>rows and cells of the templates. Those numeri...</td>\n",
       "      <td>COREP_Annex_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corep_0002</td>\n",
       "      <td>Abbreviations  \\n10. For the purposes of thi...</td>\n",
       "      <td>COREP_Annex_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corep_0003</td>\n",
       "      <td>s of certain types of undertakings, amending D...</td>\n",
       "      <td>COREP_Annex_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corep_0004</td>\n",
       "      <td>\\n11. The CA templates contain information abo...</td>\n",
       "      <td>COREP_Annex_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>pra_0079</td>\n",
       "      <td>.246 [Deleted.]\\n01/09/2022\\n2.247 [Deleted.]0...</td>\n",
       "      <td>PRA_RULEBOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>pra_0080</td>\n",
       "      <td>22\\n6.257 [Note: Provision left blank]\\n01/09/...</td>\n",
       "      <td>PRA_RULEBOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>pra_0081</td>\n",
       "      <td>/09/2022\\n6.269 Annex XVI Template F 32.04 can...</td>\n",
       "      <td>PRA_RULEBOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>pra_0082</td>\n",
       "      <td>found here\\nO .\\n01/09/2022\\n6.279 Annex XVII...</td>\n",
       "      <td>PRA_RULEBOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>pra_0083</td>\n",
       "      <td>022\\n2.287 [Deleted.]\\n01/09/2022\\n2.288 [Dele...</td>\n",
       "      <td>PRA_RULEBOOK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>646 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       chunk_id                                               text  \\\n",
       "0    corep_0000  erage;  \\n(b) group solvency, an overview of t...   \n",
       "1    corep_0001   rows and cells of the templates. Those numeri...   \n",
       "2    corep_0002    Abbreviations  \\n10. For the purposes of thi...   \n",
       "3    corep_0003  s of certain types of undertakings, amending D...   \n",
       "4    corep_0004  \\n11. The CA templates contain information abo...   \n",
       "..          ...                                                ...   \n",
       "641    pra_0079  .246 [Deleted.]\\n01/09/2022\\n2.247 [Deleted.]0...   \n",
       "642    pra_0080  22\\n6.257 [Note: Provision left blank]\\n01/09/...   \n",
       "643    pra_0081  /09/2022\\n6.269 Annex XVI Template F 32.04 can...   \n",
       "644    pra_0082   found here\\nO .\\n01/09/2022\\n6.279 Annex XVII...   \n",
       "645    pra_0083  022\\n2.287 [Deleted.]\\n01/09/2022\\n2.288 [Dele...   \n",
       "\n",
       "             source  \n",
       "0    COREP_Annex_II  \n",
       "1    COREP_Annex_II  \n",
       "2    COREP_Annex_II  \n",
       "3    COREP_Annex_II  \n",
       "4    COREP_Annex_II  \n",
       "..              ...  \n",
       "641    PRA_RULEBOOK  \n",
       "642    PRA_RULEBOOK  \n",
       "643    PRA_RULEBOOK  \n",
       "644    PRA_RULEBOOK  \n",
       "645    PRA_RULEBOOK  \n",
       "\n",
       "[646 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final = pd.concat([data1,data2],ignore_index=True)\n",
    "data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ea1e9cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bad_patterns = r\"\\[Deleted\\]|\\[ Deleted \\]|Provision left blank|can be found here|\\[Deleted\\.\\]\"\n",
    "\n",
    "data_final = data_final[\n",
    "    ~data_final[\"text\"].str.contains(bad_patterns, regex=True, flags=re.IGNORECASE)\n",
    "].copy()\n",
    "\n",
    "data_final = data_final.reset_index(drop=True)\n",
    "keep_keywords = r\"COREP|own funds|CET1|Tier 1|Tier 2|capital requirements|CRR\"\n",
    "\n",
    "pra_useful = data_final[\n",
    "    (data_final[\"source\"] == \"PRA_RULEBOOK\") &\n",
    "    (data_final[\"text\"].str.contains(keep_keywords, regex=True, flags=re.IGNORECASE))\n",
    "]\n",
    "\n",
    "corep_all = data_final[data_final[\"source\"] == \"COREP_Annex_II\"]\n",
    "\n",
    "data_final = pd.concat([corep_all, pra_useful], ignore_index=True)\n",
    "data_final = data_final.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9ee51524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad35d9ba63446889ca31f5787db18a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "embeddings = model.encode(\n",
    "    data_final[\"text\"].tolist(),\n",
    "    show_progress_bar=True,normalize_embeddings=True\n",
    ")\n",
    "\n",
    "embeddings = np.array(embeddings).astype(\"float32\")\n",
    "data_final[\"embedding_text\"] = list(embeddings)\n",
    "\n",
    "# for i in data_final['text']:\n",
    "#     data_final['text'] = model.encode(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "54ebe6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>embedding_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>corep_0000</td>\n",
       "      <td>erage;  \\n(b) group solvency, an overview of t...</td>\n",
       "      <td>COREP_Annex_II</td>\n",
       "      <td>[-0.011413075, 0.050157834, -0.06911405, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corep_0001</td>\n",
       "      <td>rows and cells of the templates. Those numeri...</td>\n",
       "      <td>COREP_Annex_II</td>\n",
       "      <td>[-0.05913836, 0.056985375, -0.046240084, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corep_0002</td>\n",
       "      <td>Abbreviations  \\n10. For the purposes of thi...</td>\n",
       "      <td>COREP_Annex_II</td>\n",
       "      <td>[-0.05379025, 0.00073226163, 0.024320433, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corep_0003</td>\n",
       "      <td>s of certain types of undertakings, amending D...</td>\n",
       "      <td>COREP_Annex_II</td>\n",
       "      <td>[-0.048888933, 0.013849427, 0.017130297, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corep_0004</td>\n",
       "      <td>\\n11. The CA templates contain information abo...</td>\n",
       "      <td>COREP_Annex_II</td>\n",
       "      <td>[-0.013768392, 0.037880532, 0.020612482, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>pra_0041</td>\n",
       "      <td>tional liquidity monitoring metrics specified ...</td>\n",
       "      <td>PRA_RULEBOOK</td>\n",
       "      <td>[0.017277189, -0.051744733, -0.06506463, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>pra_0042</td>\n",
       "      <td>to report information on asset encumbrance in ...</td>\n",
       "      <td>PRA_RULEBOOK</td>\n",
       "      <td>[-0.02410535, 0.074167915, -0.041559182, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>pra_0044</td>\n",
       "      <td>ial holding\\ncompanies and UK parent mixed fin...</td>\n",
       "      <td>PRA_RULEBOOK</td>\n",
       "      <td>[-0.004714869, -0.03567785, 0.015623904, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>pra_0045</td>\n",
       "      <td>book, the following shall apply with regard to...</td>\n",
       "      <td>PRA_RULEBOOK</td>\n",
       "      <td>[-0.0073001846, 0.019241735, -0.05826596, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>pra_0046</td>\n",
       "      <td>tutions shall submit the information referred ...</td>\n",
       "      <td>PRA_RULEBOOK</td>\n",
       "      <td>[-0.03741316, 0.058972333, -0.088498734, -0.04...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>594 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       chunk_id                                               text  \\\n",
       "0    corep_0000  erage;  \\n(b) group solvency, an overview of t...   \n",
       "1    corep_0001   rows and cells of the templates. Those numeri...   \n",
       "2    corep_0002    Abbreviations  \\n10. For the purposes of thi...   \n",
       "3    corep_0003  s of certain types of undertakings, amending D...   \n",
       "4    corep_0004  \\n11. The CA templates contain information abo...   \n",
       "..          ...                                                ...   \n",
       "589    pra_0041  tional liquidity monitoring metrics specified ...   \n",
       "590    pra_0042  to report information on asset encumbrance in ...   \n",
       "591    pra_0044  ial holding\\ncompanies and UK parent mixed fin...   \n",
       "592    pra_0045  book, the following shall apply with regard to...   \n",
       "593    pra_0046  tutions shall submit the information referred ...   \n",
       "\n",
       "             source                                     embedding_text  \n",
       "0    COREP_Annex_II  [-0.011413075, 0.050157834, -0.06911405, -0.02...  \n",
       "1    COREP_Annex_II  [-0.05913836, 0.056985375, -0.046240084, -0.06...  \n",
       "2    COREP_Annex_II  [-0.05379025, 0.00073226163, 0.024320433, -0.0...  \n",
       "3    COREP_Annex_II  [-0.048888933, 0.013849427, 0.017130297, -0.01...  \n",
       "4    COREP_Annex_II  [-0.013768392, 0.037880532, 0.020612482, -0.03...  \n",
       "..              ...                                                ...  \n",
       "589    PRA_RULEBOOK  [0.017277189, -0.051744733, -0.06506463, -0.01...  \n",
       "590    PRA_RULEBOOK  [-0.02410535, 0.074167915, -0.041559182, -0.04...  \n",
       "591    PRA_RULEBOOK  [-0.004714869, -0.03567785, 0.015623904, -0.01...  \n",
       "592    PRA_RULEBOOK  [-0.0073001846, 0.019241735, -0.05826596, 0.00...  \n",
       "593    PRA_RULEBOOK  [-0.03741316, 0.058972333, -0.088498734, -0.04...  \n",
       "\n",
       "[594 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9fc1f60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "faiss.write_index(index, \"corep_faiss.index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5d2e73c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = data_final[[\"chunk_id\", \"source\", \"text\"]].to_dict(orient=\"records\")\n",
    "\n",
    "with open(\"corep_metadata.pkl\", \"wb\") as f:\n",
    "    pickle.dump(metadata, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "98dec1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_retrieval_system(index_path=\"corep_faiss.index\",\n",
    "                          metadata_path=\"corep_metadata.pkl\",\n",
    "                          embed_model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    \n",
    "    model = SentenceTransformer(embed_model_name)\n",
    "    index = faiss.read_index(index_path)\n",
    "\n",
    "    with open(metadata_path, \"rb\") as f:\n",
    "        metadata = pickle.load(f)\n",
    "\n",
    "    return model, index, metadata\n",
    "\n",
    "\n",
    "def retrieve_chunks(query, model, index, metadata, top_k=5):\n",
    "\n",
    "    q_vec = model.encode([query], normalize_embeddings=True)\n",
    "    q_vec = np.array(q_vec).astype(\"float32\")\n",
    "\n",
    "    distances, indices = index.search(q_vec, top_k)\n",
    "\n",
    "    results = []\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        chunk_data = metadata[idx]\n",
    "\n",
    "        results.append({\n",
    "            \"chunk_id\": chunk_data[\"chunk_id\"],\n",
    "            \"source\": chunk_data[\"source\"],\n",
    "            \"text\": chunk_data[\"text\"],\n",
    "            \"score\": float(distances[0][i])\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def definition_print(query, model, index, metadata, top_k=5):\n",
    "    retrieved = retrieve_chunks(query, model, index, metadata, top_k=top_k)\n",
    "\n",
    "    output_text = \"\"\n",
    "    for r in retrieved:\n",
    "        output_text += f\"{r['chunk_id']} | {r['source']} | score={r['score']}\\n\"\n",
    "        output_text += r[\"text\"][:300] + \"\\n\"\n",
    "        output_text += \"-----\\n\"\n",
    "\n",
    "    return output_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6924de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chunk_lookup(retrieved_chunks):\n",
    "    \"\"\"\n",
    "    Converts retrieved_chunks list into a dictionary:\n",
    "    {chunk_id: chunk_text}\n",
    "    \"\"\"\n",
    "    return {c[\"chunk_id\"]: c[\"text\"] for c in retrieved_chunks}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b5b8368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_NAME = \"models/gemini-3-flash-preview\"\n",
    "import re\n",
    "\n",
    "ROW_EXTRACT = re.compile(r\"(\\d{4})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "517ed861",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROW_KEYWORDS = {\n",
    "    \"0010\": [\"own funds\", \"total own funds\"],\n",
    "    \"0015\": [\"tier 1\", \"tier 1 capital\"],\n",
    "    \"0020\": [\"common equity tier 1\", \"cet1\"],\n",
    "    \"0030\": [\"additional tier 1\", \"at1\"],\n",
    "    \"0040\": [\"tier 2\", \"tier 2 capital\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "66e44c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_evidence(result_json, retrieved_chunks):\n",
    "    \"\"\"\n",
    "    Checks if each populated cell has source chunks containing relevant keywords.\n",
    "    Adds validation flags if evidence looks wrong.\n",
    "    \"\"\"\n",
    "    flags = result_json.get(\"validation_flags\", [])\n",
    "    chunk_lookup = build_chunk_lookup(retrieved_chunks)\n",
    "\n",
    "    for cell in result_json.get(\"populated_cells\", []):\n",
    "        row = cell.get(\"row\")\n",
    "        source_ids = cell.get(\"source_chunk_ids\", [])\n",
    "\n",
    "        if not row or row not in ROW_KEYWORDS:\n",
    "            continue\n",
    "\n",
    "        expected_keywords = ROW_KEYWORDS[row]\n",
    "\n",
    "        # If no chunk ids at all\n",
    "        if not source_ids:\n",
    "            flags.append({\n",
    "                \"type\": \"missing_data\",\n",
    "                \"message\": f\"Row {row} has no source_chunk_ids evidence.\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Combine all evidence text\n",
    "        combined_text = \"\"\n",
    "        missing_chunks = []\n",
    "\n",
    "        for cid in source_ids:\n",
    "            if cid in chunk_lookup:\n",
    "                combined_text += \" \" + chunk_lookup[cid].lower()\n",
    "            else:\n",
    "                missing_chunks.append(cid)\n",
    "\n",
    "        # Chunk IDs not found in retrieved set\n",
    "        if missing_chunks:\n",
    "            flags.append({\n",
    "                \"type\": \"warning\",\n",
    "                \"message\": f\"Row {row} references chunk_ids not in retrieved context: {missing_chunks}\"\n",
    "            })\n",
    "\n",
    "        # Keyword validation\n",
    "        keyword_found = any(kw.lower() in combined_text for kw in expected_keywords)\n",
    "\n",
    "        if not keyword_found:\n",
    "            flags.append({\n",
    "                \"type\": \"warning\",\n",
    "                \"message\": f\"Row {row} evidence may be incorrect. None of {expected_keywords} found in provided source chunks.\"\n",
    "            })\n",
    "\n",
    "    result_json[\"validation_flags\"] = flags\n",
    "    return result_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ccb6f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_evidence_keywords(result_json, retrieved_chunks):\n",
    "    flags = []\n",
    "\n",
    "    chunk_map = {c[\"chunk_id\"]: c[\"text\"].lower() for c in retrieved_chunks}\n",
    "\n",
    "    row_keywords = {\n",
    "        \"0030\": [\"additional tier 1\", \"at1\", \"article 52\"],\n",
    "        \"0040\": [\"tier 2\", \"t2\", \"article 62\"],\n",
    "        \"0010\": [\"own funds\", \"total own funds\", \"article 72\"],\n",
    "        \"0015\": [\"tier 1\", \"article 25\"],\n",
    "        \"0020\": [\"common equity tier 1\", \"cet1\", \"article 50\"]\n",
    "    }\n",
    "\n",
    "    for cell in result_json.get(\"populated_cells\", []):\n",
    "        row = cell.get(\"row\")\n",
    "        chunk_ids = cell.get(\"source_chunk_ids\", [])\n",
    "\n",
    "        if row not in row_keywords:\n",
    "            continue\n",
    "\n",
    "        combined_text = \"\"\n",
    "        for cid in chunk_ids:\n",
    "            combined_text += \" \" + chunk_map.get(cid, \"\")\n",
    "\n",
    "        if not any(k in combined_text for k in row_keywords[row]):\n",
    "            flags.append({\n",
    "                \"type\": \"warning\",\n",
    "                \"message\": f\"Row {row} evidence may be incorrect. None of expected keywords {row_keywords[row]} found in cited source chunks.\"\n",
    "            })\n",
    "\n",
    "    return flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e1f47689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_thousand_reporting(result_json):\n",
    "    \"\"\"\n",
    "    COREP reports values in 000 GBP (thousands).\n",
    "    Ensures all values are integers and unit is consistent.\n",
    "    \"\"\"\n",
    "\n",
    "    # -------- populated_cells fix --------\n",
    "    for cell in result_json.get(\"populated_cells\", []):\n",
    "        val = cell.get(\"value\")\n",
    "\n",
    "        # Convert string numbers to int\n",
    "        if isinstance(val, str):\n",
    "            val = int(val.replace(\",\", \"\").strip())\n",
    "\n",
    "        # Convert full GBP to 000 GBP if too large\n",
    "        if isinstance(val, (int, float)) and val > 1000000:\n",
    "            val = int(val / 1000)\n",
    "\n",
    "        # Save cleaned value\n",
    "        cell[\"value\"] = int(val) if val is not None else None\n",
    "        cell[\"unit\"] = \"000 GBP\"\n",
    "\n",
    "    # -------- audit_log fix --------\n",
    "    for log in result_json.get(\"audit_log\", []):\n",
    "        val = log.get(\"value\")\n",
    "\n",
    "        # Convert string numbers to int\n",
    "        if isinstance(val, str):\n",
    "            val = int(val.replace(\",\", \"\").strip())\n",
    "\n",
    "        # Convert full GBP to 000 GBP if too large\n",
    "        if isinstance(val, (int, float)) and val > 1000000:\n",
    "            val = int(val / 1000)\n",
    "\n",
    "        log[\"value\"] = int(val) if val is not None else None\n",
    "\n",
    "    return result_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "60d758a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_rowwise_context(model, index, metadata, scenario, top_k=5):\n",
    "    row_queries = {\n",
    "        \"0020\": \"COREP C 01.00 row 0020 Common Equity Tier 1 capital CET1 instructions Article 50 CRR\",\n",
    "        \"0030\": \"COREP C 01.00 row 0030 Additional Tier 1 capital AT1 instructions Article 52 CRR\",\n",
    "        \"0040\": \"COREP C 01.00 row 0040 Tier 2 capital instructions Article 62 CRR\",\n",
    "        \"0015\": \"COREP C 01.00 row 0015 Tier 1 capital instructions Tier 1 = CET1 + AT1\",\n",
    "        \"0010\": \"COREP C 01.00 row 0010 Own Funds instructions Own Funds = Tier 1 + Tier 2\"\n",
    "    }\n",
    "\n",
    "    retrieved_all = []\n",
    "\n",
    "    for row, query in row_queries.items():\n",
    "        chunks = retrieve_chunks(query, model, index, metadata, top_k=top_k)\n",
    "        retrieved_all.extend(chunks)\n",
    "\n",
    "    # remove duplicates\n",
    "    seen = set()\n",
    "    merged = []\n",
    "    for c in retrieved_all:\n",
    "        if c[\"chunk_id\"] not in seen:\n",
    "            merged.append(c)\n",
    "            seen.add(c[\"chunk_id\"])\n",
    "\n",
    "    # sort by score descending\n",
    "    merged = sorted(merged, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5271cf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_row_codes(result_json):\n",
    "    if result_json is None:\n",
    "        return None\n",
    "\n",
    "    # Fix populated_cells\n",
    "    for cell in result_json.get(\"populated_cells\", []):\n",
    "        raw_row = str(cell.get(\"row\", \"\"))\n",
    "        match = ROW_EXTRACT.search(raw_row)\n",
    "        if match:\n",
    "            cell[\"row\"] = match.group(1)\n",
    "\n",
    "    # Fix audit_log\n",
    "    for log in result_json.get(\"audit_log\", []):\n",
    "        raw_field = str(log.get(\"field\", \"\"))\n",
    "        match = ROW_EXTRACT.search(raw_field)\n",
    "        if match:\n",
    "            log[\"field\"] = match.group(1)\n",
    "\n",
    "    return result_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7ccc5fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_gemini_client(api_key: str):\n",
    "    \"\"\"\n",
    "    Initializes Gemini client using a key passed at runtime.\n",
    "    \"\"\"\n",
    "    if not api_key or api_key.strip() == \"\":\n",
    "        raise ValueError(\"❌ API key is missing or empty\")\n",
    "\n",
    "    return genai.Client(api_key=api_key)\n",
    "\n",
    "\n",
    "\n",
    "client = init_gemini_client(API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8e6c7dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema_template():\n",
    "    return \"\"\"\n",
    "{\n",
    "  \"template\": \"C 01.00\",\n",
    "  \"currency\": \"GBP\",\n",
    "  \"scenario_summary\": \"\",\n",
    "  \"populated_cells\": [\n",
    "    {\n",
    "      \"row\": \"\",\n",
    "      \"column\": \"\",\n",
    "      \"item\": \"\",\n",
    "      \"value\": null,\n",
    "      \"unit\": \"GBP\",\n",
    "      \"confidence\": \"\",\n",
    "      \"source_chunk_ids\": []\n",
    "    }\n",
    "  ],\n",
    "  \"validation_flags\": [\n",
    "    {\n",
    "      \"type\": \"missing_data|inconsistency|warning\",\n",
    "      \"message\": \"\"\n",
    "    }\n",
    "  ],\n",
    "  \"audit_log\": [\n",
    "    {\n",
    "      \"field\": \"\",\n",
    "      \"value\": null,\n",
    "      \"justification\": \"\",\n",
    "      \"source_chunk_ids\": []\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "635a239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(retrieved_chunks):\n",
    "    context = \"\"\n",
    "    for chunk in retrieved_chunks:\n",
    "        context += f\"[{chunk['chunk_id']} | {chunk['source']}]\\n\"\n",
    "        context += chunk[\"text\"] + \"\\n\\n\"\n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "59059187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_million_values(result_json):\n",
    "    \"\"\"\n",
    "    Fixes values that are mistakenly returned in MILLIONS instead of 000 GBP.\n",
    "\n",
    "    Expected output unit: 000 GBP\n",
    "    Example:\n",
    "        If model outputs 480 (meaning 480 million),\n",
    "        convert to 480000 (000 GBP)\n",
    "\n",
    "    But if model already outputs 480000 (already correct in 000 GBP),\n",
    "    do NOT touch it.\n",
    "    \"\"\"\n",
    "\n",
    "    def normalize(val):\n",
    "        if val is None:\n",
    "            return None\n",
    "\n",
    "        # convert numeric strings\n",
    "        if isinstance(val, str):\n",
    "            val = val.strip().replace(\",\", \"\")\n",
    "            if val.isdigit():\n",
    "                val = int(val)\n",
    "            else:\n",
    "                try:\n",
    "                    val = float(val)\n",
    "                except:\n",
    "                    return None\n",
    "\n",
    "        # Only convert if it's clearly \"millions-style\" output\n",
    "        # Typical millions numbers will be like 80, 480, 2500 etc.\n",
    "        if isinstance(val, (int, float)):\n",
    "            if val < 100000:   # safe threshold (values like 480, 2500, 80000)\n",
    "                return int(val * 1000)  # million GBP -> 000 GBP\n",
    "            else:\n",
    "                return int(val)\n",
    "\n",
    "        return val\n",
    "\n",
    "    # Fix populated_cells\n",
    "    for cell in result_json.get(\"populated_cells\", []):\n",
    "        cell[\"value\"] = normalize(cell.get(\"value\"))\n",
    "        cell[\"unit\"] = \"000 GBP\"\n",
    "\n",
    "    # Fix audit_log\n",
    "    for log in result_json.get(\"audit_log\", []):\n",
    "        log[\"value\"] = normalize(log.get(\"value\"))\n",
    "\n",
    "    return result_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d1928c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gemini(client, prompt, model_name=MODEL_NAME):\n",
    "    response = client.models.generate_content(\n",
    "        model=model_name,\n",
    "        contents=prompt\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "861b5e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_output(llm_output):\n",
    "    llm_output = re.sub(r\"```json|```\", \"\", llm_output).strip()\n",
    "\n",
    "    try:\n",
    "        return json.loads(llm_output)\n",
    "    except:\n",
    "        print(\"❌ JSON Parsing Failed. Raw output below:\\n\")\n",
    "        print(llm_output)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "49b3b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_corep_json(client, question, scenario, retrieved_chunks):\n",
    "    schema_template = get_schema_template()\n",
    "\n",
    "    prompt = build_prompt(\n",
    "        question=question,\n",
    "        scenario=scenario,\n",
    "        retrieved_chunks=retrieved_chunks,\n",
    "        schema_template=schema_template\n",
    "    )\n",
    "\n",
    "    llm_output = call_gemini(client, prompt)\n",
    "\n",
    "    structured_json = parse_json_output(llm_output)\n",
    "\n",
    "    return structured_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "59cb3f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_mapping_text():\n",
    "    return \"\"\"\n",
    "STRICT ROW MAPPING FOR TEMPLATE C 01.00:\n",
    "- 0010 = Own Funds\n",
    "- 0015 = Tier 1 Capital\n",
    "- 0020 = Common Equity Tier 1 (CET1)\n",
    "- 0030 = Additional Tier 1 (AT1)\n",
    "- 0040 = Tier 2 Capital\n",
    "\n",
    "RULE:\n",
    "Tier 1 (0015) = CET1 (0020) + AT1 (0030)\n",
    "Own Funds (0010) = Tier 1 (0015) + Tier 2 (0040)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "95c31628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(question, scenario, retrieved_chunks, schema_template):\n",
    "    context = build_context(retrieved_chunks)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a PRA COREP regulatory reporting assistant.\n",
    "\n",
    "TASK:\n",
    "Populate COREP Own Funds Template C 01.00.\n",
    "\n",
    "STRICT RULES:\n",
    "- Output MUST be valid JSON only.\n",
    "- DO NOT output markdown.\n",
    "- DO NOT invent new row numbers.\n",
    "- Use ONLY these row codes: 0010, 0015, 0020, 0030, 0040.\n",
    "- Each populated cell MUST include source_chunk_ids.\n",
    "- source_chunk_ids MUST ONLY come from the retrieved context below.\n",
    "- If evidence is not present in context, set value=null and add a validation flag.\n",
    "- confidence MUST be exactly one of: High, Medium, Low (case-sensitive).\n",
    "\n",
    "CALCULATION RULES:\n",
    "- Tier 1 Capital (Row 0015) = CET1 (Row 0020) + AT1 (Row 0030)\n",
    "- Own Funds (Row 0010) = Tier 1 (Row 0015) + Tier 2 (Row 0040)\n",
    "\n",
    "IMPORTANT NUMERIC RULES:\n",
    "- Scenario values are given in MILLIONS of GBP.\n",
    "- All output values MUST be reported in THOUSANDS (000 GBP).\n",
    "  Example: 540 million GBP must be written as 540000 (000 GBP units).\n",
    "- Unit must ALWAYS be exactly: \"000 GBP\"\n",
    "- In justification, always show values in 000 GBP format (not full GBP, not millions).\n",
    "\n",
    "Scenario:\n",
    "{scenario}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Retrieved regulatory context:\n",
    "{context}\n",
    "\n",
    "Return JSON strictly following this schema:\n",
    "{schema_template}\n",
    "\n",
    "IMPORTANT:\n",
    "Output must start with {{ and end with }} only.\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1b52ca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_corep_output(result_json):\n",
    "    flags = []\n",
    "\n",
    "    # Convert populated_cells into dict by row for quick lookup\n",
    "    row_map = {cell[\"row\"]: cell[\"value\"] for cell in result_json[\"populated_cells\"]}\n",
    "\n",
    "    # Convert values to int if they are strings\n",
    "    def to_int(x):\n",
    "        if x is None:\n",
    "            return None\n",
    "        return int(x)\n",
    "\n",
    "    cet1 = to_int(row_map.get(\"0020\"))   # CET1 in 000 GBP\n",
    "    at1  = to_int(row_map.get(\"0030\"))   # AT1 in 000 GBP\n",
    "    tier1 = to_int(row_map.get(\"0015\"))  # Tier1 in 000 GBP\n",
    "    tier2 = to_int(row_map.get(\"0040\"))  # Tier2 in 000 GBP\n",
    "    own_funds = to_int(row_map.get(\"0010\"))  # Own Funds in 000 GBP\n",
    "\n",
    "    # Rule 1: Tier 1 = CET1 + AT1\n",
    "    if cet1 is not None and at1 is not None and tier1 is not None:\n",
    "        expected_tier1 = cet1 + at1\n",
    "        if tier1 != expected_tier1:\n",
    "            flags.append({\n",
    "                \"type\": \"inconsistency\",\n",
    "                \"message\": f\"Tier 1 mismatch (000 GBP): expected {expected_tier1}, got {tier1}\"\n",
    "            })\n",
    "\n",
    "    # Rule 2: Own Funds = Tier 1 + Tier 2\n",
    "    if tier1 is not None and tier2 is not None and own_funds is not None:\n",
    "        expected_own_funds = tier1 + tier2\n",
    "        if own_funds != expected_own_funds:\n",
    "            flags.append({\n",
    "                \"type\": \"inconsistency\",\n",
    "                \"message\": f\"Own Funds mismatch (000 GBP): expected {expected_own_funds}, got {own_funds}\"\n",
    "            })\n",
    "\n",
    "    # Rule 3: Missing required rows\n",
    "    required_rows = [\"0010\", \"0015\", \"0020\", \"0030\", \"0040\"]\n",
    "    for r in required_rows:\n",
    "        if r not in row_map:\n",
    "            flags.append({\n",
    "                \"type\": \"missing_data\",\n",
    "                \"message\": f\"Missing required row {r}\"\n",
    "            })\n",
    "\n",
    "    return flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "597593af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_evidence(audit_log, retrieved_chunks, snippet_len=300):\n",
    "    chunk_map = {c[\"chunk_id\"]: c[\"text\"] for c in retrieved_chunks}\n",
    "\n",
    "    for entry in audit_log:\n",
    "        evidence = []\n",
    "        for cid in entry.get(\"source_chunk_ids\", []):\n",
    "            if cid in chunk_map:\n",
    "                evidence.append(chunk_map[cid][:snippet_len])\n",
    "        entry[\"evidence_snippets\"] = evidence\n",
    "\n",
    "    return audit_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "79ed466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_audit_log(audit_log):\n",
    "    for entry in audit_log:\n",
    "        print(\"FIELD:\", entry.get(\"field\"))\n",
    "        print(\"VALUE:\", entry.get(\"value\"))\n",
    "        print(\"JUSTIFICATION:\", entry.get(\"justification\"))\n",
    "        print(\"SOURCE CHUNKS:\", entry.get(\"source_chunk_ids\"))\n",
    "        if \"evidence_snippets\" in entry:\n",
    "            print(\"EVIDENCE:\", entry[\"evidence_snippets\"])\n",
    "        print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "21b77eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_unique_chunks(chunks1, chunks2):\n",
    "    seen = set()\n",
    "    merged = []\n",
    "\n",
    "    for c in chunks1 + chunks2:\n",
    "        if c[\"chunk_id\"] not in seen:\n",
    "            merged.append(c)\n",
    "            seen.add(c[\"chunk_id\"])\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c192857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_corep_context(question, scenario, model, index, metadata, top_k=5):\n",
    "    \"\"\"\n",
    "    Row-wise retrieval:\n",
    "    Retrieves separate evidence for each COREP row.\n",
    "    Ensures Tier2 + Own Funds get proper chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    base_query = f\"\"\"\n",
    "Scenario:\n",
    "{scenario}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\".strip()\n",
    "\n",
    "    # Row-specific retrieval queries\n",
    "    row_queries = {\n",
    "        \"0010\": \"COREP Template C 01.00 Row 0010 Own Funds Article 72 CRR total own funds definition\",\n",
    "        \"0015\": \"COREP Template C 01.00 Row 0015 Tier 1 capital Article 25 CRR CET1 plus AT1 definition\",\n",
    "        \"0020\": \"COREP Template C 01.00 Row 0020 Common Equity Tier 1 capital Article 50 CRR deductions Article 36 CRR\",\n",
    "        \"0030\": \"COREP Template C 01.00 Row 0030 Additional Tier 1 capital AT1 instruments Article 52 CRR Article 53 CRR\",\n",
    "        \"0040\": \"COREP Template C 01.00 Row 0040 Tier 2 capital Article 62 CRR Tier 2 instruments definition\"\n",
    "    }\n",
    "\n",
    "    retrieved_all = []\n",
    "\n",
    "    # Retrieve for user question normally\n",
    "    retrieved_main = retrieve_chunks(base_query, model, index, metadata, top_k=top_k)\n",
    "    retrieved_all.extend(retrieved_main)\n",
    "\n",
    "    # Retrieve row-wise\n",
    "    for row, rq in row_queries.items():\n",
    "        retrieved_row = retrieve_chunks(rq, model, index, metadata, top_k=top_k)\n",
    "        retrieved_all.extend(retrieved_row)\n",
    "\n",
    "    # Remove duplicates by chunk_id\n",
    "    seen = set()\n",
    "    unique_chunks = []\n",
    "    for c in retrieved_all:\n",
    "        if c[\"chunk_id\"] not in seen:\n",
    "            unique_chunks.append(c)\n",
    "            seen.add(c[\"chunk_id\"])\n",
    "\n",
    "    # Sort by score descending\n",
    "    unique_chunks = sorted(unique_chunks, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    return unique_chunks[:top_k * 5]   # return bigger context\n",
    "   # keep more context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2b9ece08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corep_assistant(client, question, scenario, model, index, metadata, top_k=8):\n",
    "\n",
    "    retrieved_chunks = retrieve_rowwise_context(\n",
    "    model=model,\n",
    "    index=index,\n",
    "    metadata=metadata,\n",
    "    scenario=scenario,\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "\n",
    "    result_json = generate_corep_json(\n",
    "        client=client,\n",
    "        question=question,\n",
    "        scenario=scenario,\n",
    "        retrieved_chunks=retrieved_chunks\n",
    "    )\n",
    "\n",
    "    if result_json is None:\n",
    "        return {\"error\": \"LLM output invalid JSON\"}\n",
    "\n",
    "    result_json[\"validation_flags\"] = validate_corep_output(result_json)\n",
    "\n",
    "    result_json = fix_row_codes(result_json)\n",
    "    result_json = fix_million_values(result_json)\n",
    "    result_json = validate_evidence(result_json, retrieved_chunks)\n",
    "    extra_flags = validate_evidence_keywords(result_json, retrieved_chunks)\n",
    "    result_json[\"validation_flags\"].extend(extra_flags)\n",
    "    result_json = fix_thousand_reporting(result_json)\n",
    "\n",
    "\n",
    "\n",
    "    # attach evidence snippets\n",
    "    if \"audit_log\" in result_json:\n",
    "        result_json[\"audit_log\"] = attach_evidence(result_json[\"audit_log\"], retrieved_chunks)\n",
    "\n",
    "    return {\n",
    "        \"structured_json\": result_json,\n",
    "        \"audit_log\": result_json.get(\"audit_log\", []),\n",
    "        \"retrieved_chunks\": retrieved_chunks\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "78801788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_corep_table(result_json):\n",
    "    \"\"\"\n",
    "    Converts structured JSON output into a human-readable COREP template extract.\n",
    "    Returns a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    if result_json is None:\n",
    "        return None\n",
    "\n",
    "    populated_cells = result_json.get(\"populated_cells\", [])\n",
    "\n",
    "    if len(populated_cells) == 0:\n",
    "        print(\"⚠️ No populated cells found in JSON.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(populated_cells)\n",
    "\n",
    "    # Ensure consistent ordering of columns\n",
    "    expected_cols = [\"row\", \"column\", \"item\", \"value\", \"unit\", \"confidence\", \"source_chunk_ids\"]\n",
    "    for col in expected_cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "\n",
    "    df = df[expected_cols]\n",
    "\n",
    "    # Convert chunk ids list into readable string\n",
    "    df[\"source_chunk_ids\"] = df[\"source_chunk_ids\"].apply(lambda x: \", \".join(x) if isinstance(x, list) else x)\n",
    "\n",
    "    return df\n",
    "def print_corep_template(df):\n",
    "    if df is None or df.empty:\n",
    "        print(\"⚠️ COREP template table is empty.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n📌 COREP Template Extract (C 01.00)\\n\")\n",
    "    display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce765e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corep_assistant' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScenario:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mscenario\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQuestion:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# definition_print(query, model, index, metadata, top_k=5)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcorep_assistant\u001b[49m(client, question, scenario, model, index, metadata, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstructured_json\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_flags\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     19\u001b[0m print_audit_log(output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudit_log\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corep_assistant' is not defined"
     ]
    }
   ],
   "source": [
    "scenario = \"\"\"\n",
    "CET1 = 540 million GBP\n",
    "AT1 = 100 million GBP\n",
    "Tier 2 = 80 million GBP\n",
    "Intangible assets deduction = 40 million GBP\n",
    "Deferred tax assets deduction = 20 million GBP\n",
    "\"\"\"\n",
    "\n",
    "question = \"How should Additional Tier 1 capital and Total Own Funds be reported in COREP template C 01.00?\"\n",
    "\n",
    "query = f\"Scenario:\\n{scenario}\\n\\nQuestion:\\n{question}\"\n",
    "\n",
    "definition_print(query, model, index, metadata, top_k=5)\n",
    "\n",
    "output = corep_assistant(client, question, scenario, model, index, metadata, top_k=8)\n",
    "\n",
    "print(output[\"structured_json\"][\"validation_flags\"])\n",
    "print_audit_log(output[\"audit_log\"])\n",
    "print(json.dumps(output[\"audit_log\"], indent=4))\n",
    "result_json = output[\"structured_json\"]\n",
    "\n",
    "corep_df = json_to_corep_table(result_json)\n",
    "\n",
    "print_corep_template(corep_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9eeddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".dl-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
